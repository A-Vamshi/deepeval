---
# id: moonshot
title: Moonshot
sidebar_label: Moonshot
---

DeepEval's integration with Moonshot AI allows you to use any Moonshot models to power all of DeepEval's metrics.

### Command Line

To configure your Moonshot model through the CLI, run the following command:

```bash
deepeval set-moonshot \
    --model "kimi-k2-0711-preview" \
    --api-key "your-api-key" \
    --temperature=0
```

:::info
The CLI command above sets Moonshot as the default provider for all metrics, unless overridden in Python code. To use a different default model provider, you must first unset Moonshot:

```bash
deepeval unset-moonshot
```

:::

### Python

Alternatively, you can define `KimiModel` directly in python code:

```python
from deepeval.models import KimiModel
from deepeval.metrics import AnswerRelevancyMetric

model = KimiModel(
    model_name="kimi-k2-0711-preview",
    api_key="your-api-key",
    temperature=0
)

answer_relevancy = AnswerRelevancyMetric(model=model)
```

There are **TWO** mandatory and **ONE** optional parameters when creating an `KimiModel`:

- `model`: A string specifying the name of the Kimi model to use.
- `api_key`: A string specifying your Kimi API key for authentication.
- [Optional] `temperature`: A float specifying the model temperature. Defaulted to 0.
- [Optional] `generation_kwargs`: A dictionary of additional generation parameters supported by your model provider, such as:
    - `top_p`: Controls nucleus sampling (probability mass for token selection).
    - `max_tokens`: Maximum number of tokens in the generated response.
    - `stop_sequences`: A string or list of strings where the generation will stop.
    - `presence_penalty`: Penalizes new tokens based on whether they appear in the text so far (reduces repetition).
    - `frequency_penalty`: Penalizes new tokens based on their existing frequency in the text (reduces frequent token usage).
    - `logit_bias`: A dictionary mapping token IDs to bias values to increase or decrease likelihood.
    - `n`: Number of completions to generate per prompt.
    - `seed`: Seed for reproducibility (when supported).
    - `tools` / `tool_choice`: Parameters related to tool usage for tool-using models.
    - `logprobs`, `top_logprobs`: Return token-level log probabilities (if supported).

:::tip
Any `**kwargs` you would like to use for your model can be passed through the `generation_kwargs` parameter. However, we request you to double check the params supported by the model and your model provider in their [official docs](https://docs.together.ai/docs/inference-parameters).
:::

### Available Moonshot Models

Below is a comprehensive list of available Moonshot models:

- `kimi-k2-0711-preview`
- `kimi-thinking-preview`
- `moonshot-v1-8k`
- `moonshot-v1-32k`
- `moonshot-v1-128k`
- `moonshot-v1-8k-vision-preview`
- `moonshot-v1-32k-vision-preview`
- `moonshot-v1-128k-vision-preview`
- `kimi-latest-8k`
- `kimi-latest-32k`
- `kimi-latest-128k`
