---
# id: anthropic
title: Anthropic
sidebar_label: Anthropic
---

DeepEval supports using any Anthropic model for all evaluation metrics. To get started, you'll need to set up your Anthropic API key.

### Setting Up Your API Key

To use Anthropic for `deepeval`'s LLM-based evaluations (metrics evaluated using an LLM), provide your `ANTHROPIC_API_KEY` in the CLI:

```bash
export ANTHROPIC_API_KEY=<your-anthropic-api-key>
```

Alternatively, if you're working in a notebook environment (e.g., Jupyter or Colab), set your `ANTHROPIC_API_KEY` in a cell:

```bash
%env ANTHROPIC_API_KEY=<your-anthropic-api-key>
```

### Python

To use Anthropic models for DeepEval metrics, define an `AnthropicModel` and specify the model you want to use. By default, the `model` is set to `claude-3-7-sonnet-latest`.

```python
from deepeval.models import AnthropicModel
from deepeval.metrics import AnswerRelevancyMetric

model = AnthropicModel(
    model="claude-3-7-sonnet-latest",
    temperature=0
)
answer_relevancy = AnswerRelevancyMetric(model=model)
```

There are **TWO** optional parameters when creating an `AnthropicModel`:

- [Optional] `model`: A string specifying which of Anthropic's Claude models to use. Defaulted to `'claude-3-7-sonnet-latest'`.
- [Optional] `temperature`: A float specifying the model temperature. Defaulted to 0.
- [Optional] `generation_kwargs`: A dictionary of additional generation parameters supported by OpenAI models, such as:
    - `top_p`: Controls nucleus sampling (probability mass for token selection).
    - `max_tokens`: Maximum number of tokens in the generated response.
    - `stop`: A string or list of strings where the generation will stop.
    - `presence_penalty`: Penalizes new tokens based on whether they appear in the text so far (reduces repetition).
    - `frequency_penalty`: Penalizes new tokens based on their existing frequency in the text (reduces frequent token usage).
    - `logit_bias`: A dictionary mapping token IDs to bias values to increase or decrease likelihood.
    - `n`: Number of completions to generate per prompt.
    - `seed`: Seed for reproducibility (when supported).
    - `tools` / `tool_choice`: Parameters related to tool usage for tool-using models.
    - `logprobs`, `top_logprobs`: Return token-level log probabilities (if supported).

### Available Anthropic Models

:::note
This list only displays some of the available models. For a comprehensive list, refer to the Anthropic's official documentation.
:::

Below is a list of commonly used Anthropic models:

- `claude-3-7-sonnet-latest`
- `claude-3-5-haiku-latest`
- `claude-3-5-sonnet-latest`
- `claude-3-opus-latest`
- `claude-3-sonnet-20240229`
- `claude-3-haiku-20240307`
- `claude-instant-1.2`
