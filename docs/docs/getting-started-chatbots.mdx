---
id: getting-started-chatbots
title: LLM Evaluation for Chatbots
sidebar_label: Chatbots
---

import { Timeline, TimelineItem } from "@site/src/components/Timeline";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import CodeBlock from "@theme/CodeBlock";
import VideoDisplay from "@site/src/components/VideoDisplayer";

Learn to evaluate any type of **chatbot**, including QA agents, customer support chatbots, and even chatrooms.

## Overview

Chatbot Evaluation is different from other types of evaluations because unlike single-turn tasks, conversations happen over multiple turns. This means your chatbot must stay context-aware across the conversation, and not just accurate in individual responses. Conversations on DeepEval are captured by a <code>ConversationalTestCase</code>, which consist of multiple turns as shown below.

![Chatbot Evaluation](https://deepeval-docs.s3.amazonaws.com/docs:conversational-test-case.png)

**In this 5 min quickstart, you'll learn how to:**

1. Prepare conversational test cases.
2. Evaluate chatbot conversations.
3. Simulate conversations.

## Prerequisites

- Install `deepeval`
- A [Confident AI account](https://app.confident-ai.com) to get an API key

:::info
We recommend logging in to Confident AI to view your chatbot evaluation report and multi-turn datasets:

```bash
deepeval login
```

:::

## Evaluate Chatbot from Existing Conversations

If you don't have access to existing conversations, you'll want to evaluate your chatbot from [simulated conversations](#evaluate-chatbots-from-simulations) instead.

<Timeline>
<TimelineItem title="Create a test case">

Create a `ConversationalTestCase` by passing in a list of `Turn`s from an existing conversation, similar to OpenAI's message format.

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.test_case import ConversationalTestCase, Turn

test_case = ConversationalTestCase(
    turns=[
        Turn(role="user", content="Hello, how are you?"),
        Turn(role="assistant", content="I'm doing well, thank you!"),
        Turn(role="user", content="How can I help you today?"),
        Turn(role="assistant", content="I'd like to buy a ticket to a Coldplay concert."),
    ]
)
```

</TimelineItem>
<TimelineItem title="Run an evaluation">

Run an evaluation on the test case using `deepeval`'s [multi-turn metrics](/docs/metrics-conversational-g-eval), or create your own using [Conversational G-Eval](/docs/metrics-conversational-g-eval).

<details>
  <summary>What multi-turn metrics are available?</summary>

Conversational test cases can only be evaluated using multi-turn metrics, which include:

- [Conversational G-Eval](/docs/metrics-conversational-g-eval)
- [Role Adherence](/docs/metrics-role-adherence)
- [Knowledge Retention](/docs/metrics-knowledge-retention)
- [Conversation Completeness](/docs/metrics-conversation-completeness)
- [Conversation Relevancy](/docs/metrics-conversation-relevancy)

</details>

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.metrics import ConversationCompletenessMetric, KnowledgeRetentionMetric
from deepeval import evaluate
...

evaluate([test_case], metrics=[ConversationCompletenessMetric(), KnowledgeRetentionMetric()])
```

</TimelineItem>
<TimelineItem title="View on Confident AI">

If you're logged in to Confident AI, you'll be automatically directed to view your chatbot evaluation report.

:::tip
We recommend logging in to Confident AI to analyze your chatbot performance in detail.

```bash
deepeval login
```

:::

<VideoDisplay src="https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Aconversation-test-report.mp4" />

</TimelineItem>
</Timeline>

## Evaluate Chatbots from Simulations

Evaluating your chatbot from [simulated conversations](/docs/getting-started-chatbots#evaluate-chatbots-from-simulations) is the recommended approach for chatbot evaluation, because it allows you to quickly test your chatbot in any scenario, including unseen ones.

<Timeline>
<TimelineItem title="Create goldens">

Create a `ConversationalGolden` by providing your user description, scenario, and expected outcome, for the conversation you wish to simulate.

:::tip
The quality and amount of details in the descriptions you provide to `ConversationalGolden` will directly impact the quality of your simulated conversations.
:::

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.dataset import ConversationalGolden

conversation_golden = ConversationalGolden(
    scenario="Andy Byron wants to purchase a VIP ticket to a Coldplay concert.",
    expected_outcome="Successful purchase of a ticket.",
    user_description="Andy Byron is the CEO of Astronomer.",
)
```

<details>
  <summary>Curating goldens in bulk</summary>

#TODO: add confident ai dataset editor

</details>

</TimelineItem>
<TimelineItem title="Setup chatbot">

Define a callback function that generates the **next chatbot response** in a conversation.

:::info
Your model callback should accept an `input`, and optionally `turns` and `thread_id`.
:::

<Tabs>
<TabItem value="python" label="Python">

```python title="main.py" showLineNumbers={true} wrapLines={true}"
from deepeval.test_case import Turn

async def model_callback(input: str, turns: List[Turn], thread_id: str) -> str:
    # Replace with your chatbot
    response = await your_chatbot(input, turns, thread_id)
    return response
```

</TabItem>
<TabItem value="openai" label="OpenAI">

```python title=main.py showLineNumbers={true} wrapLines={true} metastring="{6}"
from deepeval.test_case import Turn
from openai import OpenAI

client = OpenAI()

async def model_callback(input: str, turns: List[Turn]) -> str:
    messages = [
        {"role": "system", "content": "You are a ticket purchasing assistant"},
        *[{"role": t.role, "content": t.content} for t in turns],
        {"role": "user", "content": input},
    ]
    response = await client.chat.completions.create(model="gpt-4.1", messages=messages)
    return response.choices[0].message.content
```

</TabItem>
<TabItem value="langchain" label="LangChain">

```python title=main.py showLineNumbers={true} wrapLines={true} metastring="{11}"
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

store = {}
llm = ChatOpenAI(model="gpt-4")
prompt = ChatPromptTemplate.from_messages([("system", "You are a ticket purchasing assistant."), MessagesPlaceholder(variable_name="history"), ("human", "{input}")])
chain_with_history = RunnableWithMessageHistory(prompt | llm, lambda session_id: store.setdefault(session_id, ChatMessageHistory()), input_messages_key="input", history_messages_key="history")

async def model_callback(input: str, thread_id: str) -> str:
    response = chain_with_history.invoke(
        {"input": input},
        config={"configurable": {"session_id": thread_id}}
    )
    return response.content
```

</TabItem>
<TabItem value="llama_index" label="LlamaIndex">

```python title="main.py"  showLineNumbers={true} wrapLines={true} metastring="{9}"
from llama_index.core.storage.chat_store import SimpleChatStore
from llama_index.llms.openai import OpenAI
from llama_index.core.chat_engine import SimpleChatEngine
from llama_index.core.memory import ChatMemoryBuffer

chat_store = SimpleChatStore()
llm = OpenAI(model="gpt-4")

async def model_callback(input: str, thread_id: str) -> str:
    memory = ChatMemoryBuffer.from_defaults(chat_store=chat_store, chat_store_key=thread_id)
    chat_engine = SimpleChatEngine.from_defaults(llm=llm, memory=memory)
    response = chat_engine.chat(input)
    return response.response
```

</TabItem>
<TabItem value="openai-agents" label="OpenAI Agents">

```python title="main.py" showLineNumbers={true} wrapLines={true} metastring="{6}"
from agents import Agent, Runner, SQLiteSession

sessions = {}
agent = Agent(name="Test Assistant", instructions="You are a helpful assistant that answers questions concisely.")

async def model_callback(input: str, thread_id: str) -> str:
    if thread_id not in sessions:
        sessions[thread_id] = SQLiteSession(thread_id)
    session = sessions[thread_id]
    result = await Runner.run(agent, input, session=session)
    return result.final_output
```

</TabItem>
<TabItem value="pydantic" label="Pydantic">

```python title="main.py" showLineNumbers={true} wrapLines={true} metastring="{9}"
from pydantic_ai.messages import ModelRequest, ModelResponse, UserPromptPart, TextPart
from deepeval.test_case import Turn
from datetime import datetime
from pydantic_ai import Agent
from typing import List

agent = Agent('openai:gpt-4', system_prompt="You are a helpful assistant that answers questions concisely.")

async def model_callback(input: str, turns: List[Turn]) -> str:
    message_history = []
    for turn in turns:
        if turn.role == "user":
            message_history.append(ModelRequest(parts=[UserPromptPart(content=turn.content, timestamp=datetime.now())], kind='request'))
        elif turn.role == "assistant":
            message_history.append(ModelResponse(parts=[TextPart(content=turn.content)], model_name='gpt-4', timestamp=datetime.now(), kind='response'))
    result = await agent.run(input, message_history=message_history)
    return result.output
```

</TabItem>
</Tabs>

</TimelineItem>
<TimelineItem title="Running an evaluation">

Create a `ConversationSimulator` with the model callback you've defined, and run simulations to generate conversational test cases. Then, evaluate the test cases using `deepeval`'s [multi-turn metrics](/docs/metrics-conversation-relevancy).

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval import evaluate
from deepeval.conversation_simulator import ConversationSimulator
from deepeval.metrics import ConversationRelevancyMetric
...

# Simulate conversations
simulator = ConversationSimulator(model_callback=chatbot_callback)
conversational_test_cases = simulator.simulate(goldens=[conversation_golden])

# Evaluate conversations
evaluate(conversational_test_cases, metrics=[role_adherence, knowledge_retention])
```

</TimelineItem>
<TimelineItem title="View on Confident AI">

If you're logged in to Confident AI, you'll be automatically directed to view your chatbot evaluation report.

:::tip
We recommend logging in to Confident AI to analyze your chatbot performance in detail.

```bash
deepeval login
```

:::

<VideoDisplay src="https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Aconversation-test-report.mp4" />

</TimelineItem>
</Timeline>

## Evaluate Chatbots in Production

You'll need to <a href="/docs/conversation-simulator">simulate conversations</a> with your chatbot if you don't have conversations to evaluate.

<Timeline>
<TimelineItem title="Setup chatbot">

Setup your chatbot to return a response, given the user input and conversation history.

<Tabs>
<TabItem value="python" label="Python">

```python title="main.py" showLineNumbers={true} wrapLines={true}
async def chatbot(input, conversation_history):
    # Replace this with your chatbot's response
    return f"Chatbot response to: {input} and {conversation_history}"
```

</TabItem>
<TabItem value="openai" label="OpenAI">

```python title="main.py" showLineNumbers={true} wrapLines={true}
import openai
import json

client = openai.OpenAI()

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        messages.append({"role": turn["role"], "content": turn["content"]})

    # Add current user input
    messages.append({"role": "user", "content": input})

    # Replace with your chatbot's response
    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages
    )
    return response.choices[0].message.content
```

</TabItem>
<TabItem value="langchain" label="LangChain">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from langchain.schema import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
import json

llm = ChatOpenAI(model="gpt-4")

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        if turn["role"] == "user":
            messages.append(HumanMessage(content=turn["content"]))
        else:
            messages.append(AIMessage(content=turn["content"]))

    # Add current user input
    messages.append(HumanMessage(content=input))

    # Replace with your chatbot's response
    response = await llm.ainvoke(messages)
    return response.content
```

</TabItem>
<TabItem value="langgraph" label="LangGraph">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, AIMessage
import json

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        if turn["role"] == "user":
            messages.append(HumanMessage(content=turn["content"]))
        else:
            messages.append(AIMessage(content=turn["content"]))

    # Add current user input
    messages.append(HumanMessage(content=input))

    # Replace with your chatbot's response
    state = {"messages": messages}
    result = await your_graph.ainvoke(state)
    return result["messages"][-1].content
```

</TabItem>
<TabItem value="llama_index" label="LlamaIndex">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from llama_index.core.llms import ChatMessage, MessageRole
from llama_index.core.chat_engine import SimpleChatEngine
import json
...

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        role = MessageRole.USER if turn["role"] == "user" else MessageRole.ASSISTANT
        messages.append(ChatMessage(role=role, content=turn["content"]))

    # Add current user input
    messages.append(ChatMessage(role=MessageRole.USER, content=input))

    # Replace with your chatbot's response
    response = await chat_engine.achat(input, chat_history=messages[:-1])
    return str(response)
```

</TabItem>
<TabItem value="openai-agents" label="OpenAI Agents">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from agents import Agent, Runner, SQLiteSession
import json
...

agent = Agent(name="Assistant", instructions="You are a helpful assistant")
session = SQLiteSession("conversation_session")

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    history_items = []
    for turn in history:
        history_items.append({"role": turn["role"], "content": turn["content"]})
    await session.add_items(history_items)

    # Replace with your chatbot's response
    result = await Runner.run(agent, input, session=session)
    return result.final_output
```

</TabItem>
<TabItem value="pydantic" label="Pydantic AI">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from pydantic_ai import Agent
from pydantic_ai.messages import ModelRequest, ModelResponse, UserPromptPart, TextPart
import json
...

agent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    message_history = []
    for turn in history:
        if turn["role"] == "user":
            message_history.append(
                ModelRequest(parts=[UserPromptPart(content=turn["content"])])
            )
        else:
            message_history.append(
                ModelResponse(parts=[TextPart(content=turn["content"])])
            )

    # Replace with your chatbot's response
    result = await agent.run(input, message_history=message_history)
    return result.data
```

</TabItem>
</Tabs>

</TimelineItem>
<TimelineItem title="Define user profile">

Define user profiles to interact with your chatbot.

```python title="main.py" showLineNumbers={true} wrapLines={true}
user_profiles = [
  'Garry Tan, YC Partner. Probably has a keyboard with only the Enter key.',
  'Jessica Livingston, YC Partner. Can spot a unicorn before it’s even born.'
]
```

</TimelineItem>
<TimelineItem title="Simulate conversations">

Run simulations with the user profiles and chatbot callback function you previously defined.

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.conversation_simulator import ConversationSimulator
...

simulator = ConversationSimulator(user_profiles=user_profiles)
test_cases = simulator.simulate(chatbot)
```

</TimelineItem>
</Timeline>
